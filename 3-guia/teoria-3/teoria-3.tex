\begin{enumerate}[label=\tiny\purple{\faIcon{snowman}}]
  \item \textit{Recuerdo nomenclatura de matrices}

        \begin{minipage}{0.5\textwidth}
          \textit{Nombres usados en matrices en $\reales$:}
          \begin{itemize}
            \item Ortogonal: $Q \en \reales^{n \times n}$  con $Q^tQ = I$
                  \begin{enumerate}[label={\tiny\faIcon{atom}}]
                    \item Las columnas de $Q$ forman una BON de $\reales^n$
                    \item Es ortogonalmente diagonalizable.
                    \item Preserva la norma en la multiplicación.
                    \item $\det(U) = \pm1$
                  \end{enumerate}

            \item Simétrica: $A \en \reales^{n \times n}$  con $A^t = A$
                  \begin{enumerate}[label={\tiny\faIcon{atom}}]
                    \item $A$ tiene autovalores reales.
                    \item Es ortogonalmente diagonalizable.
                  \end{enumerate}

          \end{itemize}
        \end{minipage}
        \begin{minipage}{0.5\textwidth}
          \textit{Nombres usados en matrices en $\complejos$:}
          \begin{itemize}
            \item Unitaria: $U \en \complejos^{n \times n}$  con $U^*U = I$
                  \begin{enumerate}[label={\tiny\faIcon{atom}}]
                    \item Las columnas de $U$ forman una BON de $\complejos^n$
                    \item Es ortogonalmente diagonalizable.
                    \item Preserva la norma en la multiplicación.
                    \item $\det(U) = \pm1$
                  \end{enumerate}

            \item Hermitiana: $A \en \complejos^{n \times n}$  con $A^* = A$
                  \begin{enumerate}[label={\tiny\faIcon{atom}}]
                    \item $A$ tiene autovalores reales.
                    \item Es ortogonalmente diagonalizable.
                  \end{enumerate}

          \end{itemize}
        \end{minipage}

  \item \hypertarget{teoria-3:matrizOrtogonal}{\textit{Matriz Ortogonal}}:
        \parrafoDestacado[{{ \huge \angry} }]{
          Una matriz \red{ortogonal} tiene sus columnas \underline{\red{\Large ortonormales}}.
        }
        \begin{itemize}
          \item Si $A$ es una \textit{matriz ortogonal} entonces $A^{-1} = A^*$.
          \item Si $A$ y $B$ son \textit{matrices ortogonales} entonces $AB$ es una \textit{matriz ortogonal}.
        \end{itemize}

  \item \hypertarget{teoria-3:definida-positiva}{\textit{Matriz definida positiva:}}

        Sea  $A \en \reales^{n \times n}$ definida positiva:
        $$
          \paratodo x \distinto 0 \quad x^t A x > 0 \text{ con } x \en \reales^n
        $$
        Algunas propiedades de las matrices definidas positivas:
        \begin{itemize}
          \item  $A\en \reales^{n \times n}  \textit{ simétrica definida positiva} \entonces A \text{ es inversible}$
          \item  Los elementos diagonales de una matriz \textit{simétrica definida positiva} son positivos
          \item  Las submatrices principales también son matrices definidas positivas
        \end{itemize}
        $$
          \begin{tikzpicture}[
              rect/.style={
                  draw,
                  thick,
                  minimum width=0.8cm,
                  minimum height=0.8cm
                },
              submatriz/.style={
                  draw,
                  thick,
                  anchor = center,
                  inner sep = 0pt,
                  color=#1,
                  rounded corners=0pt
                }
            ]

            \matrix (A) [
              matrix of nodes,
              nodes={draw = white,
                  rect,
                  anchor=center,
                  font=\small},
              left delimiter=(,
              right delimiter=),
              column sep=0\pgflinewidth,
              row sep=0\pgflinewidth
            ] {
              $a_{11}$ & $a_{12}$ & $a_{13}$ & $a_{14}$ \\
              $a_{21}$ & $a_{22}$ & $a_{23}$ & $a_{24}$ \\
              $a_{31}$ & $a_{32}$ & $a_{33}$ & $a_{34}$ \\
              $a_{41}$ & $a_{42}$ & $a_{43}$ & $a_{44}$ \\
            };
            \node[submatriz=orange, fit=(A-1-1)(A-3-3)] {};
            \node[submatriz=OliveGreen, fit=(A-1-1)(A-2-2)] {};
            \node[submatriz=Cerulean, fit=(A-1-1)] {};

            \node[right=0.3cm of A, align=left] {
              $
                \begin{array}{cc}
                  \blue{\blacksquare}   & \text{submatriz } 1 \times 1 \\
                  \green{\blacksquare}  & \text{submatriz } 2 \times 2 \\
                  \orange{\blacksquare} & \text{submatriz } 3 \times 3 \\
                \end{array}
              $
            };
          \end{tikzpicture}
        $$

    \item\hypertarget{teoria-3:lu}{\textit{Descomposición $LU$:} \quad $A = LU$}
        \begin{enumerate}[label={\tiny\faIcon{pray}$_{\arabic*)}$}]
          \item Sea $A \en K^{n \times n}$, \red{$A$ inversible}, entonces:
                $$
                  A \text{ tiene descomposición } LU \sii
                  \ub{A(1:k,1:k)}{\text{submatrices}\\ \text{principales}}
                  \textit{ es inversible } \paratodo k \en [1,n]
                $$
          \item Sea $A \en K^{n \times n}$, \red{$A$ inversible}, entonces:
                $$
                  A \text{ tiene descomposición } LU
                  \entonces
                  \text{ esa factorización es única }
                $$
        \end{enumerate}

  \item \textit{Descomposición $LU$ con swap de filas:} \quad $PA = LU$

  \item \hypertarget{teoría-3:cholesky}{\textit{Descomposición de Cholesky:}}

        La descomposición de Cholesky para una matriz $A$ simétrica y definida positiva:
        $$
          A = L L^t
        $$
        con $L$ triangular inferior. A partir de la descomposición:
        $$
          A = \ob{\tilde{L} U}{\text{la misma LU de siempre}}
          \flecha{\quad\magic\quad}
          A = \tilde{L}
          \ua{D}{\text{matriz diagonal}\\ \text{con los elementos}\\ \text{diagonales de } U} \tilde{L}^t
          .
        $$
        \parrafoDestacado[\atencion]{
          $A = \tilde{L} D \tilde{L}^t$, es definida positiva si y solo si
          $D$ lo es. Como $D$ es diagonal, solo es cuestión de ver que $[D]_{ii} > 0$.
        }
        Finalmente:
        $$
          A = \tilde{L} D \tilde{L}
          \sii
          A = \tilde{L} \sqrt{D} \sqrt{D} \tilde{L}^t
          \sii
          A = LL^t
        $$

  \item \hypertarget{teoria-3:proyector}{\textit{Proyectores:}}

        Se llama  \textit{Proyector} a una transformación lineal $P$ que cumple que:
        \begin{itemize}
          \item $P(v) = v$
          \item $P \circ P = P$
        \end{itemize}
        Si $P: V \to V$ es proyector, están las siguientes propiedades:
        \begin{enumerate}[label=\poo]
          \item $v - P(v) \en \nucleo(P) \paratodo v \en V$
          \item  $ \nucleo(P) \sumaDirecta \imagen(P) = V$
                lo mismo que decir que
                $\nucleo(P) \inter \imagen(P) = \set{\bm{0}}$
          \item $P$ un \textit{\blue{proyector ortogonal}}
                $\sii \nucleo(P) \perp \imagen(P)$
          \item $P$ es un \textit{\blue{proyector ortogonal}} expresado en una base \textit{\magenta{ortonormal}}
                $\entonces P = P^t \quad (P = P^* \en \complejos)$

          \item \textit{Proyector ortogonal sobre un subespacio $S \subset V$, con $\dim(S) = r$ y $\dim(V) = n$}:
                $$
                  \ua{B_S}{\text{BOG}} = \ob{\set{s_1,\ldots,s_r}}{s_i\accion s_j = 0\\ \paratodo i \distinto j}
                  \quad
                  \Entonces{proyecto $\blue{v}$}[en $S$]
                  \quad
                  P_S (\blue{v}) =
                  \ub{
                    \frac{s_1^t \accion \blue{v}}{\norma{s_1}^2} \cdot s_1 +
                    \cdots +
                    \frac{s_r^t \accion \blue{v}}{\norma{s_r}^2} \cdot s_r
                  }
                  {
                    \text{es una suma de múltiplos}\\ \text{de los generadores de } S \text{\red{\atencion}}
                  }
                $$
                Si tenés una BON de $S$ mirá como podés hacer esto más \textit{mecánico}:
                $$
                  \ua{B_S}{\text{BON}} = \ob{\set{s_1,\ldots,s_r}}{s_i\accion s_j = 0\\ \norma{s_i} = 1\\ \paratodo i \distinto j}
                  \Entonces{me armo el proyector}[al $S$ con matrices]
                $$
                $$
                  P_S =
                  \ub{
                    \matriz{c|c|c}{
                      &  &  \\
                      s_1 & \cdots & s_r \\
                      &  &
                    }
                  }{Q}
                  \ub{
                    \matriz{ccc}{
                      \quad  & s_1^t &\quad  \\ \hline
                      \quad  & \vdots &\quad \\ \hline
                      \quad  & s_r^t &\quad
                    }
                  }{Q^*}
                $$
                \textit{Now behold and be amazed maderfoca!}:
                $$
                  P_S(\blue{v}) =
                  \ub{
                    \matriz{c|c|c}{
                      &  &  \\
                      s_1 & \cdots & s_r \\
                      &  &
                    }
                  }{ \en K^{n \times r}}
                  \ub{
                    \matriz{ccc}{
                      \quad  & s_1^t &\quad  \\ \hline
                      \quad  & \vdots &\quad \\ \hline
                      \quad  & s_r^t &\quad
                    }
                  }{ \en K^{r \times n}}
                  \ub{
                    \blue{
                      \matriz{c}{
                        v_1\\
                        \vdots\\
                        v_n
                      }
                    }
                  }{ \en K^{n \times 1}}
                  \igual{\red{!}}
                  \matriz{c|c|c}{
                    &  &  \\
                    s_1 & \cdots & s_r \\
                    &  &
                  }
                  \ub{
                    \matriz{c}{
                      s_1^t \accion \blue{v}\\ \hline
                      \vdots\\ \hline
                      s_r^t \accion \blue{v}
                    }
                  }{ \en K^{r \times 1}}
                  \igual{\red{!}}
                $$
                Para hacerlo explicitamente escribo las cordenadas de un vector de $S$ como
                $s_i = (s_{i_1}, \ldots, s_{i_n} )$
                $$
                  \igual{\red{!}}
                  \ub{
                    \matriz{c}{
                      (s_1^t \accion \blue{v}) \cdot s_{1_1} + \dots + (s_r^t \accion \blue{v}) s_{r_1} \\ \hline
                      \vdots \qquad \vdots\\ \hline
                      (s_1^t \accion \blue{v}) \cdot s_{1_i} + \dots + (s_r^t \accion \blue{v}) s_{r_i}\\ \hline
                      \vdots \qquad \vdots\\ \hline
                      (s_1^t \accion \blue{v}) \cdot s_{1_n} + \dots + (s_r^t \accion \blue{v}) s_{r_n}
                    }
                  }{
                    \en K^{n \times 1}
                  }
                  \igual{\red{!!}}
                  \ob{
                    \ub{
                      s_1^t \accion \blue{v}
                    }{
                      \en K
                    }
                    \matriz{c}{
                      s_{1_1}\\
                      \vdots\\
                      s_{1_n}
                    }
                    +
                    \cdots
                    +
                    \ub{
                      s_r^t \accion \blue{v}
                    }{
                      \en K
                    }
                    \matriz{c}{
                      s_{r_1}\\
                      \vdots\\
                      s_{r_n}
                    }
                  }{
                    \text{es una suma de múltiplos}\\\text{de los generadores de } S \text{ \red{\atencion}}
                  }
                  =
                $$
                $$
                  = (s_1^t \accion \blue{v}) \cdot s_1 + \cdots +  (s_r^t \accion \blue{v}) \cdot s_r =
                  P_S(\blue{v})
                $$
                Donde en \red{!!} es acomodar ese vector gordo que está a la izquierda como una suma de vectores flacos multiplicados
                por un escalar. Y listo queda la proyección igual que antes solo que con una base \red{ortonormal}.
        \end{enumerate}

  \item \textit{Gram-Schmidt:}
        \begin{enumerate}[label={\tiny\faIcon{pray}$_{\arabic*)}$}]
          \item Proceso para construir una base que generá el mismo espacio, pero con elementos perpediculares entre sí.
                $$
                  \ub{\set{v_1, \ldots, v_r}}{\text{Base inicial}}
                  \flecha{Gram-Schmidt}
                  \ub{\set{\purple{u_1}, \ldots, \purple{u_r}}}{\text{Base final}}
                  \quad \text{con } u_i \cdot u_j = 0 \paratodo i \distinto j
                $$

          \item La mecánica es cuentosa pero razonable:
                \begin{enumerate}[label=\arabic*)]
                  \item Agarro el \underline{primer vector de la base inicial} $v_1$ como primer vector de la base final:
                        $$
                          \{\ua{\purple{u_1}}{= v_1}\}
                        $$

                  \item Agarro el \underline{segundo vector de la base inicial} $v_2$ y calculo el segundo vector de la base final:
                        $$
                          \purple{u_2} = v_2 - \frac{\purple{u_1^*} \cdot v_2}{\norma{\purple{u_1}}^2}\purple{u_1}
                          \flecha{actualizo la}[base final]
                          \set{\purple{u_1}, \purple{u_2}}
                        $$

                  \item Y voy así hasta usar todos los vectores el \underline{segundo vector de la base inicial} $v_2$ y calculo el segundo vector de la base final:
                        $$
                          \purple{u_3} = v_3
                          - \frac{\purple{u_1^*} \cdot v_3}{\norma{\purple{u_1}}^2}\purple{u_1}
                          - \frac{\purple{u_2^*} \cdot v_3}{\norma{\purple{u_2}}^2}\purple{u_2}
                          \flecha{actualizo la}[base final]
                          \set{\purple{u_1}, \purple{u_2}, \purple{u_3}}
                        $$

                  \item En general cuando agarre el \underline{$i-$ésimo vector de la base inicial} y calcule el $i-$ésimo vector de la base final:
                        $$
                          \purple{u_i} = v_i
                          - \sumatoria{k = 1}{i-1} \frac{\purple{u_k^*} \cdot v_i}{\norma{\purple{u_k}}^2}\purple{u_k}
                          \flecha{actualizo la}[base final]
                          \set{\purple{u_1}, \ldots, \purple{u_i}}
                        $$

                  \item Así hasta haber usado todos los vectores de la base inicial, para obtener la base con los vectores ortogonalizados:
                        $$
                          \set{\purple{u_1}, \ldots, \purple{u_r}}
                        $$
                        es una base ortogonal, para los amigos una BOG, si quiero que sea una \textit{base ortonormal}, BON:
                        $$
                          \set{\purple{\frac{u_1}{\norma{u_1}}}, \ldots, \purple{\frac{u_r}{\norma{u_r}}}}
                        $$
                \end{enumerate}
        \end{enumerate}

  \item\hypertarget{teoria-3:qr}{ \textit{Factorización $QR$:}\quad  $A = Q R$}

        La factorización $QR$ no tiene un pedo que ver con las $LU$, Chole y amigos. $QR$ es un fantasma
        \blue{\Large\faIcon{ghost}} que sale de \textit{Gram-Schmidt}.
        $$
          \ub{\set{v_1, \ldots, v_r}}{\text{Columnas de }A}
          \flecha{Gram-Schmidt}[más normalizar]
          \ub{\set{\purple{\frac{u_1}{\norma{u_1}}}, \ldots, \purple{\frac{u_r}{\norma{u_r}}}}}{\text{Columnas de }Q}
          \quad \text{con } u_i \cdot u_j = 0 \paratodo i \distinto j
        $$
        \begin{enumerate}[label=$\bm{\perp}\arabic*)$]
          \item $Q$ es una \textit{matriz ortogonal} que va a tener en sus columnas el resultado de \red{ortonormalizar} las columnas de $A$.

          \item $R$ es una \textit{matriz triangular superior} con las normas de las columnas de $Q$ en la diagonal

          \item Mini derivación:
                $$
                  \ob{
                    \purple{u_i} = v_i
                    - \sumatoria{k = 1}{i-1} \frac{\purple{u_k^*} \cdot v_i}{\norma{\purple{u_k}}_2^2}\purple{u_k}
                  }{\text{Gram-Schmidt, duro y puro}}
                  \flecha{despejo el $v_i$}[y acomodo]
                  \ob{
                    \ua{v_i}{
                      \text{col}$-i$\\\text{de} A
                    } =
                    \purple{u_i} + \sumatoria{k = 1}{i-1} \frac{\purple{u_k^*} \cdot v_i}{\norma{\purple{u_k}}} \frac{\purple{u_k}}{\norma{\purple{u_k}}}
                  }{\llamada1}
                $$
                Eso ahora lo uso para armar $A = QR$:
                $$
                  \ub{
                    \matriz{c|c|c}{
                      &  & \\
                      v_1 & v_2 & v_3\\
                      &  & \\
                    }
                  }{A}
                  =
                  \ub{
                    \matriz{c|c|c}{
                      &  & \\
                      \frac{\purple{u_1}}{\norma{\purple{u_1}}} &\frac{\purple{u_2}}{\norma{\purple{u_2}}} &\frac{\purple{u_3}}{\norma{\purple{u_3}}} \\
                      &  & \\
                    }
                  }{Q}
                  \cdot
                  \ub{
                    \matriz{c|c|c}{
                      \norma{\purple{u_1}} & \frac{\purple{u_1^*} \cdot v_2}{\norma{\purple{u_1}}} & \frac{\purple{u_1^*} \cdot v_3}{\norma{\purple{u_1}}} \\
                      0 & \norma{\purple{u_2}} & \frac{\purple{u_2^*} \cdot v_3}{\norma{\purple{u_2}}}\\
                      0 & 0 &\norma{\purple{u_3}}
                    }
                  }{R}
                $$
                Ya sé que hice el ejemplo matricial en $\reales^3$, pero con el poder de tu imaginación fijate que la columna $j-$ésima para una matriz
                imaginaria de $n\times n$ sería algo así:
                $$
                  \columna(A)_j =
                  v_j
                  \igual{$\llamada1$}
                  \sumatoria{k = 1}{j-1} \frac{\purple{u_k^*} \cdot v_j}{\norma{\purple{u_k}}} \frac{\purple{u_k}}{\norma{\purple{u_k}}}
                  +  \purple{u_j}
                $$

          \item No sé si ayuda a la notación o no, pero quiero cambiar la notación así:
                $$
                  \set{\purple{\frac{u_1}{\norma{u_1}}}, \ldots, \purple{\frac{u_r}{\norma{u_r}}}}
                  \flecha{le pongo la gorra}
                  \set{\green{\hat{u}_1}, \ldots, \green{\hat{u}_r}}
                  \text{ donde los }
                  \green{\hat{u}_i} \cdot \green{\hat{u}_j} \ua{=}{i\distinto j} 0 \ytext \norma{\green{\hat{u}}_i} = 1 \paratodo i
                $$
                Dejando así la expresión de la descomposión:
                $$
                  \ub{
                    \matriz{c|c|c}{
                      &  & \\
                      v_1 & v_2 & v_3\\
                      &  & \\
                    }
                  }{A}
                  =
                  \ub{
                    \matriz{c|c|c}{
                      &  & \\
                      \green{\hat{u}_1} & \green{\hat{u}_2} &\green{\hat{u}_3} \\
                      &  & \\
                    }
                  }{Q \text{ con cols \red{ortonormales}} }
                  \cdot
                  \ub{
                    \matriz{c|c|c}{
                      \norma{\purple{u_1}} & \green{\hat{u}_1^*} \cdot v_2 & \green{\hat{u}_1^*} \cdot v_3 \\
                      0 & \norma{\purple{u_2}} & \green{\hat{u}_2^*} \cdot v_3 \\
                      0 & 0 &\norma{\purple{u_3}}
                    }
                  }{R \text{ triangular superior}}
                $$
        \end{enumerate}

  \item \textit{Matriz de HouseHolder:}
        \hacer
\end{enumerate}
